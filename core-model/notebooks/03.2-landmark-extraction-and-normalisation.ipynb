{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cee9891-4874-43ff-9818-176588adccc3",
   "metadata": {},
   "source": [
    "# Landmark Extraction & Normalisation – Quick Test  \n",
    "This notebook loads a few sample images, extracts the 21 MediaPipe hand landmarks,\n",
    "normalises them (centre at wrist, scale with peak-to-peak) and flattens to a\n",
    "63-element vector.  \n",
    "We will visualise the landmarks and ensure the helper functions work before\n",
    "processing the full dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "252a3098-17bc-4a48-99f5-cd9268598015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d4cc0e-eed5-432e-bd48-e05764f333a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1751813581.483099   15214 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1751813581.495900   15214 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "MP_HANDS=mp.solutions.hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=1,\n",
    "        model_complexity=1,\n",
    "        min_detection_confidence=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b934303-7121-4dc1-acae-c8bdab06a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────── single-image → vector ─────────────────────────────\n",
    "def one_image_to_vector(img_path: Path):\n",
    "    \"\"\"\n",
    "    Return (label, 65-D vector) or error message if:\n",
    "      • class == 'nothing'\n",
    "      • no hand detected\n",
    "      • image corrupted\n",
    "    \"\"\"\n",
    "    label = img_path.parent.name\n",
    "    if label == \"nothing\":\n",
    "        return label, \"class_nothing\"\n",
    "\n",
    "    img_bgr = cv2.imread(str(img_path))\n",
    "    if img_bgr is None:\n",
    "        return label, \"corrupt_image\"\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    lm_res = MP_HANDS.process(img_rgb)\n",
    "    if not lm_res.multi_hand_landmarks:\n",
    "        return label, \"no_hand\"\n",
    "\n",
    "    # (21,3) array -> centre on wrist\n",
    "    lm = np.array([[p.x, p.y, p.z] for p in lm_res.multi_hand_landmarks[0].landmark],\n",
    "                  dtype=np.float32)\n",
    "    lm -= lm[0]                                   # wrist at origin\n",
    "    scale = np.max(np.ptp(lm, axis=0)) or 1.0     # global peak-to-peak\n",
    "    lm /= scale                                   # normalise\n",
    "\n",
    "    # 1️⃣ original 60-D vector (drop wrist → 20×3)\n",
    "    vec60 = lm[1:].flatten()\n",
    "\n",
    "    # 2️⃣ NEW 5-D distances wrist → finger tips\n",
    "    tip_ids = [4, 8, 12, 16, 20]                  # thumb, index, middle, ring, pinky\n",
    "    dists = [float(np.linalg.norm(lm[i])) for i in tip_ids]  # already scaled\n",
    "\n",
    "    # final vector length = 60 + 5 = 65\n",
    "    return label, vec60.tolist() + dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d84476-f203-4b83-9189-b551adb157ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1751813586.903945   15211 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch matrix: (20, 65)\n",
      "Max |mean|: 4.71289673953379e-15\n",
      "Min/std: 0.9999999999999998 Max/std: 1.0000000000000002\n",
      "✔️ StandardScaler behaves as expected with the 65-D features.\n"
     ]
    }
   ],
   "source": [
    "K = 20\n",
    "all_imgs = list(Path(\"../data/filtered/clean/A\").rglob(\"*.jpg\"))\n",
    "batch    = random.sample(all_imgs, K)\n",
    "\n",
    "vecs = []\n",
    "fail_reasons = {\"class_nothing\": 0, \"no_hand\": 0, \"corrupt_image\": 0}\n",
    "\n",
    "for p in batch:\n",
    "    _, result = one_image_to_vector(p)\n",
    "    if isinstance(result, list):  # good result\n",
    "            vecs.append(result)\n",
    "    else:\n",
    "            fail_reasons[result] += 1\n",
    "\n",
    "X_batch = np.stack(vecs)\n",
    "print(\"Batch matrix:\", X_batch.shape)   # (≤K, 65)\n",
    "\n",
    "scaler  = StandardScaler().fit(X_batch)\n",
    "X_scaled = scaler.transform(X_batch)\n",
    "\n",
    "means = X_scaled.mean(axis=0)\n",
    "stds  = X_scaled.std(axis=0)\n",
    "\n",
    "print(\"Max |mean|:\", np.abs(means).max())\n",
    "print(\"Min/std:\", stds.min(), \"Max/std:\", stds.max())  # all ~1\n",
    "\n",
    "assert np.allclose(means, 0, atol=1e-6)\n",
    "assert np.allclose(stds, 1, atol=1e-6)\n",
    "print(\"✔️ StandardScaler behaves as expected with the 65-D features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d3ed0-fa2d-4f20-9bc4-c5d6e874b017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
